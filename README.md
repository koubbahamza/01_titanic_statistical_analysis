ğŸ§  Titanic â€” Data Analysis & Machine Learning Pipeline
ğŸ¯ Objectif du projet

Ce projet consiste Ã  dÃ©velopper une analyse exploratoire complÃ¨te (EDA) et un pipeline de Machine Learning entiÃ¨rement automatisÃ© pour rÃ©soudre le cÃ©lÃ¨bre dÃ©fi Kaggle :
ğŸ‘‰ Titanic â€” Machine Learning from Disaster.

Lâ€™objectif est de :

comprendre les facteurs influenÃ§ant la survie

construire un pipeline propre, modulaire, rÃ©utilisable

entraÃ®ner un modÃ¨le Random Forest optimisÃ©

gÃ©nÃ©rer automatiquement des fichiers de submission Kaggle

structurer le projet comme un vÃ©ritable projet Data Science professionnel

ğŸ“Š DonnÃ©es utilisÃ©es

Les donnÃ©es proviennent du concours officiel Kaggle :
ğŸ”— https://www.kaggle.com/c/titanic/data

Variables principales :

Survived â€” cible (0 = mort, 1 = survÃ©cu)

Pclass â€” classe du billet (1Ã¨re Ã  3e)

Sex â€” sexe

Age â€” Ã¢ge

Fare â€” prix du billet

Embarked â€” port dâ€™embarquement

SibSp, Parch â€” famille

Cabin, Ticket, Name â€” textes Ã  transformer

ğŸ”§ Technologies & Librairies
ğŸ§ª Analyse & Manipulation

Python 3.13

Pandas, NumPy

Seaborn, Matplotlib

ğŸ¤– Machine Learning

Scikit-learn

RandomForestClassifier

cross_val_score

ğŸ— Structuration du projet

Architecture modulaire src/

Pipeline reproductible

GÃ©nÃ©ration automatique des CSV avec timestamp

Notebook pour lâ€™EDA et les tests de modÃ¨les

ğŸ§± Architecture du projet
01_titanic_statistical_analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â”œâ”€â”€ submission/
â”‚   â”‚   â”œâ”€â”€ submission_random_forest.csv
â”‚   â”‚   â””â”€â”€ submission_random_forest_2025xxxx_xxxxxx.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_data_analysis.ipynb          # EDA complÃ¨te + tests modÃ¨les
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py                 # Feature engineering, imputation, encoding
â”‚   â”œâ”€â”€ model_random_forest.py           # EntraÃ®nement RF modulaire
â”‚   â””â”€â”€ train_pipeline.py                # Pipeline ML complet (automatisÃ©)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ§© Pipeline Machine Learning

Le pipeline complet (dÃ©fini dans train_pipeline.py) suit les Ã©tapes :

1ï¸âƒ£ Chargement des donnÃ©es

train / test

concatÃ©nation dans full

2ï¸âƒ£ Feature Engineering

CrÃ©ation des variables clÃ©s :

Title (extrait du nom)

Deck (extrait de Cabin)

FamilySize

FarePerPerson

Age*Class

3ï¸âƒ£ Imputation intelligente

Age â†’ mÃ©diane par Title

Fare â†’ mÃ©diane

Embarked â†’ mode

4ï¸âƒ£ Nettoyage des colonnes inutiles

Suppression de : Name, Ticket, Cabin

5ï¸âƒ£ One-Hot Encoding global

Sur : Sex, Embarked, Title, Deck

6ï¸âƒ£ SÃ©paration train/test alignÃ©e

Garantie que les colonnes sont strictement identiques.

7ï¸âƒ£ EntraÃ®nement modÃ¨le

RandomForestClassifier

HyperparamÃ¨tres optimisÃ©s (n_estimators, max_depth, etc.)

Cross-validation (5 folds)

8ï¸âƒ£ GÃ©nÃ©ration de la submission

Predictions sur X_test

CSV exportÃ© automatiquement dans data/submission/

Nom unique avec timestamp

ğŸ§ª RÃ©sultats du modÃ¨le

Cross-validation (5 folds) :

Scores = [0.82, 0.82, 0.83, 0.81, 0.85]
Score moyen = ~0.827


Le modÃ¨le Random Forest donne des performances stables et cohÃ©rentes avec les benchmarks connus du Titanic.

ğŸš€ Comment exÃ©cuter le pipeline
1) Activer lâ€™environnement virtuel
.\.venv\Scripts\activate

2) Lancer le pipeline complet
python src/train_pipeline.py

3) RÃ©sultat

Un fichier est gÃ©nÃ©rÃ© automatiquement :

data/submission/submission_random_forest_YYYYMMDD_HHMMSS.csv


â¡ï¸ Il peut Ãªtre dÃ©posÃ© directement sur Kaggle.

ğŸ“’ Notebook d'analyse

Le notebook notebooks/01_data_analysis.ipynb contient :

EDA complÃ¨te

visualisations

corrÃ©lations

test de modÃ¨les

validation croisÃ©e

interprÃ©tations

Ce notebook sert dâ€™espace dâ€™analyse, tandis que src/ contient le pipeline propre en production.

ğŸ’¡ CompÃ©tences dÃ©veloppÃ©es

Structuration dâ€™un projet ML complet

Feature engineering avancÃ©

Traitement des valeurs manquantes

One-Hot encoding cohÃ©rent entre train/test

Cross-validation

Gestion dâ€™un pipeline automatisÃ©

GÃ©nÃ©ration de fichiers de submission

Nettoyage & industrialisation du code

ğŸ‘¤ Auteur

Hamza Koubba
Data Scientist & IoT Engineer â€¢ Industrie 4.0 â€¢ IA & R&D

ğŸ“§ hamzakoubba95@gmail.com

ğŸ”— LinkedIn : https://www.linkedin.com/in/koubba/