ğŸ§  Titanic â€” Data Analysis & Machine Learning Pipeline
ğŸ¯ Objectif du projet

Ce projet consiste Ã  dÃ©velopper une analyse exploratoire complÃ¨te (EDA) ainsi quâ€™un pipeline de Machine Learning automatisÃ© pour prÃ©dire la survie des passagers du Titanic dans le cadre du dÃ©fi Kaggle :

ğŸ‘‰ Titanic â€” Machine Learning from Disaster

Les objectifs principaux sont :

Comprendre les facteurs influenÃ§ant la survie

Construire un pipeline propre, modulaire et rÃ©utilisable

EntraÃ®ner un modÃ¨le Random Forest optimisÃ©

GÃ©nÃ©rer automatiquement des fichiers de submission Kaggle

Structurer un projet comme un vÃ©ritable workflow Data Science professionnel

ğŸ“Š DonnÃ©es utilisÃ©es

Les donnÃ©es proviennent du concours officiel Kaggle :
ğŸ”— https://www.kaggle.com/c/titanic/data

Variables principales :

Survived â€” cible (0 = mort, 1 = survÃ©cu)

Pclass â€” classe du billet

Sex, Age, Fare

Embarked â€” port dâ€™embarquement

SibSp, Parch â€” famille

Cabin, Ticket, Name â€” features textuelles Ã  transformer

ğŸ”§ Technologies & Librairies
ğŸ§ª Analyse & Manipulation

Python 3.13

Pandas, NumPy

Matplotlib, Seaborn

ğŸ¤– Machine Learning

Scikit-learn

RandomForestClassifier

cross_val_score

ğŸ— Structuration

Architecture modulaire src/

Pipeline reproductible et automatisÃ©

Export automatique de submissions (timestamp)

Notebook dÃ©diÃ© Ã  lâ€™EDA

ğŸ§± Architecture du projet
01_titanic_statistical_analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ submission/
â”‚       â”œâ”€â”€ submission_random_forest.csv
â”‚       â””â”€â”€ submission_random_forest_2025xxxx_xxxxxx.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_data_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model_random_forest.py
â”‚   â””â”€â”€ train_pipeline.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ§© Pipeline Machine Learning

Le pipeline (dÃ©fini dans train_pipeline.py) suit les Ã©tapes suivantes :

1ï¸âƒ£ Chargement des donnÃ©es

train / test

concatÃ©nation en dataset global pour le preprocessing

2ï¸âƒ£ Feature Engineering

CrÃ©ation de variables dÃ©rivÃ©es :

Title (extrait du nom)

Deck (extrait du Cabin)

FamilySize

FarePerPerson

Age*Class (interaction)

3ï¸âƒ£ Imputation intelligente

Age â†’ mÃ©diane par Title

Fare â†’ mÃ©diane

Embarked â†’ mode

4ï¸âƒ£ Nettoyage

Suppression des colonnes non exploitables :
Name, Ticket, Cabin

5ï¸âƒ£ Encodage

One-Hot Encoding global

Alignement train/test garanti

6ï¸âƒ£ EntraÃ®nement du modÃ¨le

ModÃ¨le : RandomForestClassifier

HyperparamÃ¨tres optimisÃ©s

Cross-validation 5-fold

7ï¸âƒ£ GÃ©nÃ©ration de la submission

PrÃ©diction sur X_test

Export automatique :

data/submission/submission_random_forest_YYYYMMDD_HHMMSS.csv

ğŸ“Š RÃ©sultats du modÃ¨le
Cross-validation (5 folds) :
Scores = [0.82, 0.82, 0.83, 0.81, 0.85]
Score moyen = 0.827


Ces rÃ©sultats sont cohÃ©rents avec les meilleurs benchmarks Random Forest sur Titanic.

ğŸš€ Comment exÃ©cuter le pipeline
1) Activer lâ€™environnement virtuel
.\.venv\Scripts\activate

2) Lancer le pipeline complet
python src/train_pipeline.py

3) RÃ©sultat

Un fichier de submission Kaggle est gÃ©nÃ©rÃ© automatiquement dans :

data/submission/

ğŸ“’ Notebook dâ€™analyse

Le notebook 01_data_analysis.ipynb contient :

Analyse exploratoire complÃ¨te

Visualisations et corrÃ©lations

Tests de modÃ¨les

Cross-validation

InterprÃ©tations

Il sert de zone dâ€™expÃ©rimentation, tandis que src/ contient la logique industrialisÃ©e.

ğŸ’¡ CompÃ©tences dÃ©veloppÃ©es

Structuration dâ€™un projet ML complet

Feature engineering avancÃ©

Traitement des valeurs manquantes

Encodage cohÃ©rent train/test

Cross-validation

Production de pipelines automatisÃ©s

GÃ©nÃ©ration de fichiers de submission

Industrialisation et nettoyage du code

ğŸ‘¤ Auteur

Hamza Koubba
Data Scientist & IoT Engineer â€” Industrie 4.0 â€¢ IA & R&D

ğŸ“§ hamzakoubba95@gmail.com

ğŸ”— LinkedIn : https://www.linkedin.com/in/koubba/